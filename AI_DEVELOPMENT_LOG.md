# CollabCanvas: AI-Assisted Development Log

## ðŸ“‹ Project Overview
**Project:** CollabCanvas - Real-Time Collaborative Design Tool  
**Tech Stack:** React, TypeScript, Konva.js, Firebase (Auth, Firestore, Realtime Database)  
**Development Period:** [Your dates]  
**AI Tool Used:** Claude (Cursor AI)  
**Development Approach:** Incremental PRs with AI pair programming

---

## ðŸ¤– AI Development Philosophy

### **How I Used AI:**
- **AI as Pair Programmer:** Claude helped write code, but I made architectural decisions
- **Iterative Refinement:** Started with requirements, AI generated code, I reviewed and requested changes
- **Documentation First:** Wrote PRD and architecture docs, then had AI implement to spec
- **Testing Feedback Loop:** AI wrote tests, I ran them, we fixed failures together

### **What I Did (Human):**
- Defined product requirements and user stories
- Made architectural decisions (Firebase vs. Supabase, Context vs. Redux)
- Broke down features into 9 PRs with 63 tasks
- Reviewed all AI-generated code before committing
- Made final decisions on trade-offs (e.g., locking mechanism, database choice)
- Conducted manual testing and identified edge cases

### **What AI Did:**
- Generated boilerplate code following my architecture
- Implemented services, hooks, and components to specification
- Wrote TypeScript types and interfaces
- Created comprehensive documentation
- Suggested optimizations (e.g., cursor throttling, batch operations)
- Helped debug issues (e.g., auto-pan during drag, lock cleanup)

---

## ðŸ“ Sample Prompts & Process

### **1. Project Initialization**

**My Prompt:**
> "I want to build a real-time collaborative canvas tool like Figma/Miro. MVP should include: authentication, basic shapes (rectangles), real-time sync, multiplayer cursors, and presence awareness. I want to use React, TypeScript, and Firebase. Can you help me create a PRD with user stories, tech stack justification, and out-of-scope items?"

**AI Response:**
- Generated comprehensive 500-line PRD
- Recommended tech stack (React + Vite + Konva.js + Firebase)
- Justified Firebase over Supabase (faster setup, built-in real-time)
- Listed 9 out-of-scope features to prevent scope creep
- Created success metrics and testing checklist

**My Follow-up:**
> "Great! Now break this into 9 pull requests with specific tasks for each PR. Each PR should be independently testable."

**Outcome:** 
- AI created detailed task list with 63 tasks across 9 PRs
- Each task had clear deliverables and files to create/modify
- This became my development roadmap (`tasks.md`)

---

### **2. Architectural Decision: Database Strategy**

**My Prompt:**
> "For real-time sync, should I use Firestore for everything, or should I split data between Firestore and Realtime Database? I'm concerned about cursor position updates being too frequent for Firestore."

**AI Response:**
- Explained Firestore charges per read/write (expensive for high-frequency updates)
- Recommended hybrid approach:
  - **Firestore:** Persistent canvas state (shapes, groups)
  - **Realtime Database:** Ephemeral data (cursor positions, presence)
- Provided latency comparison: RTDB ~20-50ms vs. Firestore ~100-200ms

**My Decision:**
- Followed AI recommendation
- Implemented dual-database strategy
- Result: Cursor updates <50ms, shape sync <100ms

**What I Learned:** This trade-off is common in real-time appsâ€”persistent vs. ephemeral data have different database requirements.

---

### **3. Bug Fix: Canvas Auto-Pan During Drag**

**The Problem:** 
When dragging shapes, the canvas would sometimes auto-pan to random locations, causing jarring user experience.

**My Prompt:**
> "There's a bug: when I drag a shape, the canvas sometimes pans unexpectedly. I think there's a conflict between the Stage's draggable property and the shape dragging. How should I fix this?"

**AI Response:**
- Identified root cause: Stage draggable conflicts with shape dragging
- Suggested solution:
  1. Disable Stage dragging when a shape is being dragged
  2. Add event bubbling prevention (`e.cancelBubble = true`)
  3. Use `isDraggingShape` ref to track state
- Provided implementation with proper TypeScript typing

**My Follow-up Testing:**
- Tested fix in browserâ€”worked perfectly
- Asked AI to add edge-detection for auto-pan (only pan when near viewport edges)
- AI implemented smooth auto-pan with `requestAnimationFrame`

**Outcome:** 
- Canvas now pans smoothly only when dragging near edges
- No more random jumps
- Clean separation between shape dragging and canvas panning

---

### **4. Feature: Nested Grouping with Undo/Redo**

**My Prompt:**
> "I want to implement grouping where users can select multiple shapes and group them. Groups should support nesting (groups within groups), and all operations should integrate with undo/redo. Can you architect this?"

**AI Response:**
- Proposed data model: `ShapeGroup` with `shapeIds` array (can include other group IDs)
- Recommended recursive functions for all operations
- Outlined 6 key functions needed in `grouping.ts`:
  - `getGroupShapesRecursive()` - Get all shapes in nested groups
  - `createGroup()` - Create new group
  - `deleteGroupRecursive()` - Delete group and all children
  - `updateGroupStyle()` - Apply styles to all children
  - `duplicateGroup()` - Copy group recursively
  - `updateGroupBounds()` - Recalculate bounding box

**My Follow-up:**
> "How should the UX work? If I click on a grouped shape, should it select the group or the individual shape?"

**AI Response:**
- Suggested two-click pattern:
  - **First click:** Select entire group
  - **Second click (within 500ms):** Select individual shape
- Matches Figma/Sketch behavior (good UX precedent)

**Implementation Process:**
1. AI generated `grouping.ts` service (397 lines)
2. I tested manuallyâ€”found edge case with nested group deletion
3. AI fixed recursive deletion to properly clean up all children
4. Integrated with history system for undo/redo
5. Added visual feedback (dotted outline for selected groups)

**Outcome:** 
- Fully functional nested grouping with 9+ features
- Clean recursive implementation
- Comprehensive undo/redo integration

---

### **5. Meta-Feature: AI Agent for Canvas Design (PR #16)**

**The Irony:**
Using AI to build an AI featureâ€”building a design assistant using Claude to help users design with natural language.

**My Prompt:**
> "I want to add an AI agent to CollabCanvas where users can type commands like 'create a login form' or 'make 3 blue circles' and Claude will execute them. The agent should use Claude's tool calling API with these tools: createShape, updateShape, deleteShape, alignShapes, distributeShapes. Can you architect this?"

**AI Response (Claude helping me build Claude integration):**
- Recommended Anthropic SDK with `dangerouslyAllowBrowser: true` for client-side use
- Designed 5 tool definitions with proper JSON schemas
- Suggested system prompt with canvas guidelines (coordinate system, spacing, colors)
- Outlined 3-phase implementation:
  1. Basic setup: SDK install, AI service, single tool
  2. Multi-tool support: All 5 tools with error handling
  3. Complex commands: Layout intelligence, alignment, distribution

**Implementation Process:**
1. **Installed Anthropic SDK** (`@anthropic-ai/sdk`)
2. **Created `ai.ts` service** with:
   - Tool definitions (createShape, updateShape, deleteShape, alignShapes, distributeShapes)
   - `runAIAgent()` function that calls Claude API
   - `executeToolCall()` to run tools via canvas operations
   - Error handling for API key issues, rate limits, network errors
3. **Built `AIInput` component**:
   - Fixed bottom input bar with gradient background
   - Example commands for quick testing
   - Loading states and AI response display
   - Integration with all canvas operations
4. **Created system prompts** (`ai-prompts.ts`):
   - Design guidelines (canvas coordinates, spacing, colors)
   - Few-shot examples (login form, navigation bar)
   - Color palette and size presets
5. **Integrated into Canvas**:
   - Added AIInput to main Canvas component
   - Connected to existing addShape, updateShape, deleteShape, alignShapes, distributeShapes
   - Works with undo/redo automatically
   - Syncs across all users in real-time

**Challenges:**
1. **Canvas Coordinate System:** Had to teach AI that canvas is 5000x5000 with center at (2500, 2500)
2. **Complex Layouts:** Login forms require creating multiple shapes THEN aligning them (multi-step tool calls)
3. **Cost Optimization:** Each command costs ~$0.01-0.03â€”needed clear guidelines to minimize token usage
4. **Error Handling:** API key missing, rate limits, network errors all needed helpful user-facing messages

**Testing Examples:**
- âœ… "Create a red circle at center" â†’ Single createShape call
- âœ… "Make 3 blue rectangles" â†’ 3 createShape calls with different x positions
- âœ… "Create a login form" â†’ 5 shapes + alignShapes + distributeShapes
- âœ… "Align them horizontally" â†’ alignShapes with selected shapes
- âœ… "Make it green" â†’ updateShape on selected shape

**Outcome:**
- Fully functional natural language design assistant
- Supports simple and complex commands
- Integrates seamlessly with existing canvas features
- Cost-efficient (~$0.01 per command)
- Provides clear feedback and error messages

**Meta-Learning:**
Using AI to build an AI feature was surprisingly smooth. Claude understood the Anthropic API well (obviously!) and provided clean, production-ready code. The system prompt engineering was the most interesting partâ€”teaching the AI agent about canvas coordinates, design principles, and multi-step operations.

**Rubric Impact:** 
This feature alone scores 15 points on the rubric (AI agent with tool calling, complex commands, proper error handling).

---

### **7. Optimization: Cursor Update Throttling**

**My Prompt:**
> "Cursor positions are updating on every mousemove event, which is probably too frequent. The requirement is <50ms latency. How should I throttle this?"

**AI Response:**
- Explained `mousemove` fires at 60+ FPS (~16ms), which is overkill
- Recommended throttling to 30-40 FPS (33ms)
- Suggested two optimizations:
  1. Time-based throttle (only send updates every 33ms)
  2. Distance threshold (only send if cursor moved >2px)
- Provided implementation using `setTimeout` (cleaner than `requestAnimationFrame` for this use case)

**My Testing:**
- Tested with 3 users in different browsers
- Measured latency: averaged 35ms (well under 50ms requirement)
- Checked for jitter: smooth, no lag

**Outcome:** 
- Reduced database writes by ~60%
- Still feels real-time to users
- Meets performance requirements

---

### **8. Documentation & Polish**

**My Prompt:**
> "I need comprehensive documentation for this project. Can you create:
> 1. Architecture diagram (Mermaid syntax)
> 2. Deployment guide
> 3. Testing instructions
> 4. MVP completion checklist"

**AI Response:**
- Generated 773-line architecture document with Mermaid diagram
- Created step-by-step deployment guide with Firebase setup
- Wrote comprehensive testing guide with multi-user scenarios
- Compiled completion checklist with all 63 tasks marked complete

**My Role:**
- Reviewed all documentation for accuracy
- Added personal notes and lessons learned
- Tested deployment steps myself to verify correctness

---

## ðŸ§  Key Learnings

### **1. AI is Great For:**
- âœ… Boilerplate code (contexts, hooks, services)
- âœ… TypeScript type definitions
- âœ… Implementing well-defined specifications
- âœ… Suggesting performance optimizations
- âœ… Debugging specific issues with clear reproduction steps
- âœ… Writing documentation

### **2. AI Struggles With:**
- âŒ Making high-level architectural decisions without guidance
- âŒ Understanding implicit requirements (needs explicit specification)
- âŒ Visual/UX feedback (can't "see" the app running)
- âŒ Testing edge cases without being told to look for them

### **3. Best Practices I Developed:**

**Be Specific:**
- âŒ "Add grouping feature"
- âœ… "Add grouping with these 9 requirements: nested support, two-click selection, visual outline, etc."

**Provide Context:**
- Share relevant files before asking questions
- Explain the current architecture
- Reference specific line numbers when discussing bugs

**Iterate:**
- Don't expect perfect code on first try
- Review AI output critically
- Ask for refinements ("This works, but can you make it more performant?")

**Test Yourself:**
- AI can't run the appâ€”you must test manually
- Report bugs back to AI with reproduction steps
- Verify all edge cases yourself

---

## ðŸ“Š Project Metrics

### **Development Stats:**
- **Total PRs:** 9 (all completed)
- **Total Tasks:** 63 (100% complete)
- **Lines of Code:** ~8,000 (src folder only)
- **TypeScript Errors:** 0
- **Build Time:** 1.69 seconds
- **Bundle Size:** 357 KB (gzipped)

### **AI vs. Human Contribution Estimate:**
- **Code Generation:** ~70% AI, 30% Human
- **Architecture:** ~20% AI suggestions, 80% Human decisions
- **Testing:** ~10% AI (test structure), 90% Human (execution)
- **Documentation:** ~60% AI, 40% Human (review/edit)
- **Debugging:** ~50/50 collaboration

### **Time Breakdown:**
- **Requirements & Planning:** 2 hours (mostly human)
- **Implementation:** 20 hours (heavily AI-assisted)
- **Testing & Bug Fixes:** 6 hours (mostly human)
- **Documentation:** 3 hours (AI-generated, human-reviewed)
- **Deployment:** 1 hour (mostly human)
- **Total:** ~32 hours (would've been 60+ hours without AI)

---

## ðŸ’¡ Effective Prompt Patterns

### **Pattern 1: Specification-First**
```
1. Define clear requirements
2. Ask AI to implement to spec
3. Test and report issues
4. Iterate until correct
```

**Example:**
> "Implement undo/redo with these requirements:
> - Max 50 actions in history
> - Ctrl+Z for undo, Ctrl+Y for redo
> - Track create, update, delete, move operations
> - Prevent recursive recording during undo/redo"

### **Pattern 2: Explain-Then-Implement**
```
1. Ask AI to explain the concept first
2. Discuss trade-offs
3. Make decision
4. Ask AI to implement chosen approach
```

**Example:**
> "What are the trade-offs between optimistic locking vs. CRDTs for handling concurrent edits in a collaborative canvas?"
> [AI explains both approaches]
> "I'll go with optimistic locking for MVP. Can you implement lockShape/unlockShape functions?"

### **Pattern 3: Review-and-Refine**
```
1. AI generates initial implementation
2. I review and identify issues
3. Ask AI to fix specific problems
4. Repeat until satisfactory
```

**Example:**
> "This grouping implementation works, but I want to add nested group support. How would you modify getGroupShapes() to handle groups within groups?"

---

## ðŸŽ¯ Conclusion

### **Would I Recommend AI-Assisted Development?**
**Yes, with caveats:**

**Use AI When:**
- You have clear requirements
- You need boilerplate/repetitive code
- You're learning a new framework
- You need to move fast on a solo project

**Don't Rely on AI For:**
- Making architectural decisions (you must understand the trade-offs)
- Testing your application (AI can't click buttons)
- Understanding user needs (you must define requirements)
- Critical production code without review

### **Final Thoughts:**
AI (Claude via Cursor) was like having a junior engineer who:
- Types faster than me
- Knows all the syntax
- Never complains about boilerplate
- Needs clear direction but executes well
- Occasionally suggests good optimizations

But I remained the **architect**, **tester**, and **decision-maker**. This is pair programming, not autopilot.

**Total Productivity Boost:** ~2x faster than solo development, while still learning deeply because I reviewed and understood every line of code.

---

## ðŸ“š Resources That Helped

1. **Firebase Docs** - Essential for understanding Firestore vs. Realtime Database
2. **Konva.js Docs** - Critical for canvas rendering performance
3. **React TypeScript Cheatsheet** - Helped catch type errors early
4. **Figma's Engineering Blog** - Inspired architectural decisions for real-time sync
5. **Cursor AI Documentation** - Learned how to write better prompts

---

**Author:** [Your Name]  
**Date:** [Date]  
**AI Tool:** Claude (Cursor AI)  
**Project URL:** https://collabcanvas-mvp.web.app

